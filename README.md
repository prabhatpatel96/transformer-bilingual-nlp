# Transformer-Based Bilingual Text Generation (English â†” Hindi)

ğŸš€ **Self Project** â€” Implementation of a custom Transformer model from scratch for **Englishâ€“Hindi translation**, built without high-level Transformer libraries.
**BLEU 27.8 and METEOR 0.41**
## ğŸ“Œ Project Overview
This project implements a Transformer architecture **entirely from scratch** in PyTorch for bilingual translation between English and Hindi. It is trained on the **IIT Bombay Parallel Corpus** and replicates both forward and backward passes using only PyTorchâ€™s `autograd`, without relying on high-level APIs like `nn.Transformer`.

## âœ¨ Key Features
- **Custom Transformer Implementation** â€” Encoder-Decoder architecture coded from scratch.
- **Core Modules** â€” Multi-Head Attention, Positional Encoding, Layer Normalization.
- **Manual Training Pipeline** â€” Custom forward/backward pass implementation using `autograd`.
- **Bilingual Support** â€” Trained on IIT Bombay Englishâ€“Hindi parallel dataset.
- **High Translation Accuracy** â€” Demonstrates deep understanding of NLP modeling and training dynamics.

## ğŸ› ï¸ Tech Stack
- **Language:** Python 3.x
- **Libraries:** PyTorch, NumPy, Pandas
- **Dataset:** IIT Bombay Parallel Corpus
- **Environment:** Cross-platform (Windows / Linux)

## ğŸ“‚ Project Structure
.
â”œâ”€â”€ config.py # Configuration for training and model parameters
â”œâ”€â”€ dataset.py # Dataset loading and preprocessing pipeline
â”œâ”€â”€ model.py # Transformer model implementation
â”œâ”€â”€ train.py # Training loop with custom forward/backward passes
â”œâ”€â”€ translate.py # Translation inference script
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ report.pdf # Detailed project report
â””â”€â”€ .gitignore # Ignored files and directories


## ğŸ“Š Model Architecture
- **Encoder:**
  - Input Embedding + Positional Encoding
  - Multi-Head Self-Attention
  - Feed Forward Network
- **Decoder:**
  - Masked Multi-Head Self-Attention
  - Encoderâ€“Decoder Attention
  - Feed Forward Network
- **Output:** Linear + Softmax for word prediction

## ğŸš€ Installation & Usage
### 1ï¸âƒ£ Clone Repository
```bash
git clone https://github.com/prabhatpatel96/transformer-bilingual-nlp.git
cd transformer-bilingual-nlp
2ï¸âƒ£ Install Dependencies
pip install -r requirements.txt
3ï¸âƒ£ Train the Model
python train.py
4ï¸âƒ£ Translate Text
python translate.py --text "Hello world" --direction en2hi
ğŸ“ˆ Example Translation
Input (English):
I love learning new languages.
Output (Hindi):
à¤®à¥à¤à¥‡ à¤¨à¤ˆ à¤­à¤¾à¤·à¤¾à¤à¤ à¤¸à¥€à¤–à¤¨à¤¾ à¤ªà¤¸à¤‚à¤¦ à¤¹à¥ˆà¥¤
